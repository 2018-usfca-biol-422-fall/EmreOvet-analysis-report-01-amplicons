---
title: "Analysis Report 1: Your Title Here"
author: "Emre Ovet"
date: "October 31, 2018"
output: github_document
bibliography: references.bib
csl: bioinformatics.csl
---

# Introduction

The human body hosts millions of bacterial communities that are beneficial or harmful for their host, with varying abundances and phyla. One particular organ of the human body, that is, the tissue, has been recently under the scope of the microbiologists due to the diversity and the abundance of bacterial communities on its surface. One of the research topics on the bacteria living on the skin surface investigates if it is possible to use skin bacterial communities for forensic investigations.

# Methods

## Sample origin and sequencing
We obtained our data from the keyboard analysis conducted by Fierer et al.[@fierer2010forensic] .For the keyboard analysis, keys from 3 personal computer keyboards which belong to 3 healthy individuals with ages varying from 20 to 35 years were swabbed along with the fingertips of their owners by Fierer et al.. 2 of these individuals share the same working space. The keyboards had not been touched for 30 minutes before swabbing and each keyboard swabbed by Fierer et al. between 10 minute intervals. Then, space bar keys from 15 personal or public computer keyboards located in University of Colorado Campus were swabbed. In order to sample skin surfaces and keyboards, pre- moistured and autoclaved cotton-tipped swabs were used. All the swabs were kept at -80 Celsius before DNA extraction. 

 The genomic DNA was extracted by Fierer et al. using MO BIO Powersoil DNA isolation kit [@fierer2010forensic]. Then, 16S rRNA genes were amplified and used in PCR. Furthermore, agarose gel electrophoresis was conducted to visualize the replicate amplicons. Amplicon DNA concentrations were analyzed using Quant-iTPicoGreen dsDNA reagent and kit. Then, a pellet was prepared using cleaned and quantified amplicons for pyrosequencing. Fierer et al. used 454 Life Sciences Genome Sequencer FLX instrument by the Environmental Genomics Core Facility at the University of South Carolina.
 
 For sequence analyses, the criteria established for excluding low quality sequences is that all the sequences should be 200 and 300 base pairs in length, have a quality score higher than 25, don't contain ambigious characters, uncorrectable barcode and should contain primer sequence [@fierer2010forensic].

## Computational

First of all, we started our computational analysis by loading genereal-use packages from
bioconductor and GitHub. Then, we set the base path for our input data files from
keyboard study, sorted the path to ensure samples are in order, extracted sample names and specified the full path for each of the filenames_forward_reads [@callahan2016; @mcmurdie2013]. Next, we plotted the quality profiles of each 20 samples. After checking those quality profiles,
we created a diretory called "filtered_reads_path", placed our filtered files inside the filtered/ subdirectory in it and trimmed the lower quality sequences [@callahan2016; @mcmurdie2013]. Then, we produced a table of read counts before and after trimming. This was followed by building error models from each of the samples and visualizing errors with plots to make sure error models matched our data. After checking the plots, we removed all the replicated sequences to increase DADA2's accuracy [@callahan2016; @fierer2010forensic]. Next, we ran DADA2 to apply the core sample inference algorith to the dereplicated data [@callahan2016; @mcmurdie2013]. After DADA2 ran succesfully, we created a new sequence table with "samples" rows and "sequnce variants" columns. This was followed by an histogram of sequence lenghts to check the distribution of trimmed and denoised sequences. Then, we removed the chimeras from our cleaned reads to obtain just non-chimeric reads. After that, we builded a table of pipeline read counts to see how many sequences remain at each step of the pipeline. Next, we assigned taxonomy to each sequence variant. After assigning taxonomy, we extracted sequences to Fasta and builded a phylogeny using DADA2 [@callahan2016; @mcmurdie2013]. Finally, we read in the phylogeny and construct a Phyloseq object [@fierer2010forensic; @mcmurdie2013]. After completing all these steps, we melted all 3 metadata together, explored the dataset and made plots using ggplot.

# Results

In addition to a minimum of 3-4 figures/tables (and associated captions), you should include sufficient text in this section to describe what your findings were. Remember that in the results section you just describe what you found, but you don't interpret it - that happens in the discussion.

```{r load-libraries, message = FALSE}
# Be sure to install these packages before running this script
# They can be installed either with the intall.packages() function
# or with the 'Packages' pane in RStudio

# load general-use packages
library("dplyr")
library("tidyr")
library("knitr")
library("ggplot2")

# this package allows for the easy inclusion of literature citations in our Rmd
# more info here: https://github.com/crsh/citr
# and here:
# http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html
library("citr")

# These are the primary packages well use to clean and analyze the data
# this package needs to be installed from bioconductor -- it's not on CRAN
# see info here: https://benjjneb.github.io/dada2/dada-installation.html
library("dada2")

# This to export a fasta of our final denoised sequence variants
library("seqinr")

# To install this you have to install from GitHub
# See more info here: https://github.com/leffj/mctoolsr
# run this -- install.packages("devtools")
# and then this --
library("mctoolsr")

# And this to visualize our results
# it also needs to be installed from bioconductor
library("phyloseq")
```

```{r extract-sample-and-file-names}
# NOTE: Much of the following follows the DADA2 tutorials available here:
# https://benjjneb.github.io/dada2/tutorial.html
# Accessed October 19, 2018

# set the base path for our input data files
path <- "data/raw_data"

# Sort ensures samples are in order
filenames_forward_reads <- sort(list.files(path, pattern = ".fastq"))

# Extract sample names, assuming filenames have format: SAMPLENAME.fastq
sample_names <- sapply(strsplit(filenames_forward_reads, "\\."), `[`, 1)

# Specify the full path to each of the filenames_forward_reads
filenames_forward_reads <- file.path(path, filenames_forward_reads)
```

```{r check-quality-plots}
# Plots the quality profiles of all twenty samples
plotQualityProfile(filenames_forward_reads[1:115])
```

We can see from the quality profiles that most reads tend to get pretty bad in quality after around 200 bases. 

```{r filter-reads}
# Place filtered files in filtered/ subdirectory
# note this will fail if the directory doesn't exist
filter_path <- file.path("output", "filtered")
filtered_reads_path <- file.path(filter_path,
                                 paste0(sample_names,
                                        "_filt.fastq.gz"))

# See ?filterAndTrim for details on the parameters
# See here for adjustments for 454 data:
# https://benjjneb.github.io/dada2/
#     faq.html#can-i-use-dada2-with-my-454-or-ion-torrent-data
filtered_output <- filterAndTrim(fwd = filenames_forward_reads,
                                 filt = filtered_reads_path,
                                 maxLen = 300,
                                 maxN = 0, # discard any seqs with Ns
                                 maxEE = 3, # allow w/ up to 3 expected errors
                                 truncQ = 2, # cut off if quality gets this low
                                 rm.phix = TRUE,
                                 compress = TRUE,
                                 multithread = FALSE)
```

```{r filtered-read-counts-table}
# produce nicely-formatted markdown table of read counts
# before/after trimming
kable(filtered_output,
      col.names = c("Reads In",
                    "Reads Out"))
```

```{r learn-errors}
# this build error models from each of the samples
errors_forward_reads <- learnErrors(filtered_reads_path,
                                    multithread = FALSE)
```

```{r visualize-errors-with-plots}
# quick check to see if error models match data
# (black lines match black points) and are generally decresing left to right
plotErrors(errors_forward_reads,
           nominalQ = TRUE)
```

```{r dereplicate-sequences}
# get rid of any duplicated sequences
dereplicated_forward_reads <- derepFastq(filtered_reads_path,
                                         verbose = TRUE)

# Name the derep-class objects by the sample names
names(dereplicated_forward_reads) <- sample_names
```

```{r run-dada}
# parameters adjusted based on recommendations for 454 data here:
# https://benjjneb.github.io/dada2/
#     faq.html#can-i-use-dada2-with-my-454-or-ion-torrent-data
dada_forward_reads <- dada(dereplicated_forward_reads,
                           err = errors_forward_reads,
                           HOMOPOLYMER_GAP_PENALTY = -1, # reduce penalty bc 454
                           BAND_SIZE = 32) # performs local alignments bc indels

# check dada results
dada_forward_reads
```

```{r make-sequence-table}
# produce the 'site by species matrix'
sequence_table <- makeSequenceTable(dada_forward_reads)
```

The output table has `r nrow(sequence_table)` rows (samples) and `r ncol(sequence_table)` columns (sequence variants). Notice how we can embed R code directly in our markdown text.

```{r histogram-of-sequence-lengths}
# Quick check to look at distribution of trimmed and denoised sequences
hist(nchar(getSequences(sequence_table)),
     main = "Histogram of final sequence variant lengths",
     xlab = "Sequence length in bp")
```

```{r remove-chimeras}
# Check for and remove chimeras
sequence_table_nochim <- removeBimeraDenovo(sequence_table,
                                            method = "consensus",
                                            multithread = FALSE,
                                            verbose = TRUE)

# What percent of our reads are non-chimeric?
non_chimeric_reads <- round(sum(sequence_table_nochim) / sum(sequence_table),
                            digits = 4) * 100
```

After removing chimeras, we were left with `r non_chimeric_reads`% of our cleaned reads.

```{r table-of-pipeline-read-counts}
# Build a table showing how many sequences remain at each step of the pipeline
get_n <- function(x) sum(getUniques(x)) # make a quick function
track <- cbind(filtered_output, # already has 2 columns
               sapply(dada_forward_reads, get_n),
               rowSums(sequence_table),
               rowSums(sequence_table_nochim))

# add nice meaningful column names
colnames(track) <- c("Input",
                     "Filtered",
                     "Denoised",
                     "Sequence Table",
                     "Non-chimeric")

# set the proper rownames
rownames(track) <- sample_names

# produce nice markdown table of progress through the pipeline
kable(track)
```

```{r assign-taxonomy}
# assigns taxonomy to each sequence variant based on a supplied training set
# made up of known sequences
taxa <- assignTaxonomy(sequence_table_nochim,
                       "data/training/rdp_train_set_16.fa.gz",
                       multithread = FALSE,
                       tryRC = TRUE) # also check with seq reverse compliments

# show the results of the taxonomy assignment
unname(taxa)
```

```{r extract-sequences-to-fasta}
# we want to export the cleaned, trimmed, filtered, denoised sequence variants
# so that we can build a phylogeny - we'll build the phylogeny outside of R
# but we need the fasta file to do so. We keep the names of each sequence as the
# sequence itself (which is rather confusing), because that's how DADA2 labels
# it's columns (e.g. 'species')
# function taken from https://github.com/benjjneb/dada2/issues/88
export_taxa_table_and_seqs <- function(sequence_table_nochim,
                                       file_seqtab,
                                       file_seqs) {
  seqtab_t <- as.data.frame(t(sequence_table_nochim)) # transpose to data frame
  seqs <- row.names(seqtab_t) # extract rownames
  row.names(seqtab_t) <- seqs # set rownames to sequences
  outlist <- list(data_loaded = seqtab_t)
  mctoolsr::export_taxa_table(outlist, file_seqtab) # write out an OTU table
  seqs <- as.list(seqs)
  seqinr::write.fasta(seqs, row.names(seqtab_t), file_seqs) # write out fasta
}

# actually run the function, with the names of the files we want it to create
# and where to put them
export_taxa_table_and_seqs(sequence_table_nochim,
                           "output/sequence_variants_table.txt",
                           "output/sequence_variants_seqs.fa")
```


```{r read-in-metadata-and-create-phyloseq}
# Next we want to read in the metadata file so we can add that in too
# This is not a csv file, so we have to use a slightly different syntax
# here the `sep = "\t"` tells the function that the data are tab-delimited
# and the `stringsAsFactors = FALSE` tells it not to assume that things are
# categorical variables
metadata_in <- read.table(paste0("data/metadata/",
                    "fierer_hand_bacteria_SRA_study_ERP022626_SraRunTable.txt"),
                          sep = "\t",
                          header = TRUE,
                          stringsAsFactors = FALSE,
                          row.names = 6) # sets sample IDs to row names

# read in the phylogeny, which was created from the fasta exported above
# in Geneious by aligning the sequences with MAFFT and then building a
# Maximum-Likelihood tree with RAxML
tree_in <- read_tree("output/sequence_variants_MAFFT_FastTree.newick")

# Construct phyloseq object (straightforward from dada2 outputs)
phyloseq_obj <- phyloseq(otu_table(sequence_table_nochim,
                                   taxa_are_rows = FALSE), # sample-spp matrix
                         sample_data(metadata_in), # metadata for each sample
                         tax_table(taxa), # taxonomy for each sequence variant
                         phy_tree(tree_in)) # phylogeny from sequence variants
```

```{r melt-phyloseq}
melted_phyloseq <- psmelt(phyloseq_obj)
melted_phyloseq$sample_source[
  melted_phyloseq$sample_source == "Left_Shift"] <- "Left_shift"
```
```{r exploring-datasets}
names(melted_phyloseq)
```
```{r The-most-abundant-phylum-in-each-key}
melted_phyloseq %>%
  ggplot(aes(x = sample_source,
             y = Abundance,
             fill = Phylum)) +
  geom_col(position = position_dodge()) +
  theme(axis.text = element_text(angle = 90, hjust = 1)) +
ggtitle("The Most Abundant Phylum in Each Key")
```
```{r Abundance-of-phyla-on-2-left-shift-keys-and-right-shift-keys}
melted_phyloseq %>%
  filter(sample_source %in% c("Left_shift", "Left_Shift", "Right_shift")) %>%
  ggplot(aes(x = sample_source, y = Abundance, fill = Phylum)) +
  geom_col(position = position_dodge()) +
    theme(axis.text = element_text(angle = 90, hjust = 1)) +
  ggtitle("Abundance of Phyla on 2 Left Shift Keys and Right Shift Key")

```
```{r Abundance-of-family-in-actinobacteria-phylum-found-in-left-and-right-shift-keys}
melted_phyloseq %>%
  filter(sample_source %in% c("Left_shift", "Left_Shift", "Right_shift")) %>%
  filter(Phylum %in% c("Actinobacteria")) %>%
  ggplot(aes(x = sample_source, y = Abundance, fill = Family)) +
  geom_col(position = position_dodge()) +
    theme(axis.text = element_text(angle = 90, hjust = 1)) +
  ggtitle("Abundance of family in Actinobacteria phylum found
          in left and right shift keys")

```
```{r Abundance-of-genus-in-propionibacteriaceae-family-found-in-shift-keys}
melted_phyloseq %>%
  filter(sample_source %in% c("Left_shift", "Left_Shift", "Right_shift")) %>%
  filter(Family %in% c("Propionibacteriaceae")) %>%
  ggplot(aes(x = sample_source, y = Abundance, fill = Genus)) +
  geom_col(position = position_dodge()) +
  theme(axis.text = element_text(angle = 90, hjust = 1)) +
  ggtitle("Abundance of genus in Propionibacteriaceae family
          found in left and right shift keys")
```
```{r The-host-subject-identities-for-the-Propionibacterium-genus-found-in-shift-keys}
melted_phyloseq %>%
  filter(sample_source %in% c("Left_shift", "Left_Shift", "Right_shift")) %>%
  filter(Genus %in% c("Propionibacterium")) %>%
  ggplot(aes(x = sample_source, y = Abundance, fill = host_subject_id)) +
  geom_col(position = position_dodge()) +
  theme(axis.text = element_text(angle = 90, hjust = 1)) +
  ggtitle("The Host Subject Identities For The Propionibacterium
            Genus Found In Shift Keys")
```
# Discussion

Add around 2-3 pages interpreting your results and considering future directions one might take in analyzing these data.

# Sources Cited


